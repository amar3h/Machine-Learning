<!-- rmarkdown v1 -->
---
title: "Human Activity Recognition"
author: "Andrew Marsh"
date: "May 27, 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Human Activity Recognition

Human Activity Recognition - HAR - has emerged as a key research area in the last years and is gaining increasing attention by the pervasive computing research community, especially for the development of context-aware systems. There are many potential applications for HAR, like: elderly monitoring, life log systems for monitoring energy expenditure and for supporting weight-loss programs, and digital assistants for weight lifting exercises. 

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement - a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, our goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. 

More information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset).

## Data

The training data for this project are available here:

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv


The test data are available here:

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv


The data for this project come from this source: http://groupware.les.inf.puc-rio.br/har. We are greatful to them for allowing their data to be used for our research.

## Download the Data

Load the training and test datasets into tables.
```{r, echo=TRUE}
# Training and Test Datasets
train<-read.csv("C:/amarsh/HOME/amarsh/Andrew/Data Science/Practical Machine Learning/pml-training.csv", header=T, na.strings=c("NA", "#DIV/0!"))
test<-read.csv("C:/amarsh/HOME/amarsh/Andrew/Data Science/Practical Machine Learning/pml-testing.csv", header=T, na.string=c("NA", "#DIV/0!"))
```

## Preprocess the Data
Belt, arm, dumbbell, and forearm variables that do not have any missing ("NA", "#DIV/0!"") values in the training dataset will be predictor candidates. That left us with 52 variables and 19622 class measurements in the training dataset. The same variables were maintained in the test data set to be used for predicting the 20 test cases provided. Belt, arm, dumbbell, and forearm variables that do not have any missing values in the test dataset will be predictor candidates. 

```{r, echo=TRUE}
require(data.table)
searchForNA <- sapply(test, function (x) any(is.na(x) | x == ""))
predVariables <- !searchForNA & grepl("belt|[^(fore)]arm|dumbbell|forearm", names(searchForNA))
modelVariables <- names(searchForNA)[predVariables]
modelVariables
```

Subset the model variables dataset to include only the predictor candidates and the outcome variable "classe."

```{r}
totalVariables <- c("classe", modelVariables)
trainClean <- train[,totalVariables]
testClean <- test[,modelVariables]

dim(trainClean)
names(trainClean)
dim(testClean)
```
Make classe into a factor.

```{r}
trainClean$classe <- factor(trainClean$classe) 
```

## Data Partition and Prediction Process

The cleaned downloaded data set was subset in order to generate a test set independent from the 20 cases provided set. Partitioning was performed to obtain a 80% training set and a 20% validation set.

```{r}
library(caret)
inTrain<-createDataPartition(y=trainClean$classe, p=0.75,list=F)
trainPartition<-trainClean[inTrain,] 
validationPartition<-trainClean[-inTrain,] 

dim(trainPartition)
dim(validationPartition)
```
## Results and Conclusions
Random forest trees were generated for the training dataset using cross-validation. The generated algorithm was examnined under the partitioned training set to examine the accuracy and estimated error of prediction. By using 52 predictors for five classes using cross-validation at a 5-fold an accuracy of 99.2% with a 95% CI [0.9891-0.9943] was achieved accompanied by a Kappa value of 0.9899.

```{r}
library(caret)
library(randomForest)
set.seed(666)
fitControl2<-trainControl(method="cv", number=5, allowParallel=T, verbose=T)
rffit<-train(classe~.,data=trainPartition, method="rf", trControl=fitControl2, verbose=F)
```

```{r, ECHO=TRUE}
predrf<-predict(rffit, newdata=validationPartition)
confusionMatrix(predrf,validationPartition$classe)

```

Apply the centering and scaling to the probing dataset.

```{r, echo=TRUE}
# Predict the outcome of the 20 test cases
predTest<-predict(rffit, newdata=testClean)
predTest
```

A boosting algorithm was also run to confirm and be able to compare predictions. The boosting approach presented slightly less accuracy (95.98%) with a 95% CI [0.954-0.9652] was achieved accompanied by a Kappa value of 0.9492. The predictions for the 20 test cases were very similar for both ran algorimths.

```{r, echo=TRUE}
library(gbm)
library(plyr)

fitControl2<-trainControl(method="cv", number=5, allowParallel=T, verbose=T)
gmbfit<-train(classe~.,data=trainPartition, method="gbm", trControl=fitControl2, verbose=F)
gmbfit$finalModel
class(gmbfit)
predgmb<-predict(gmbfit, newdata=validationPartition)
confusionMatrix(predgmb, validationPartition$classe)
predtrain<-predict(gmbfit, newdata=trainPartition)
confusionMatrix(predtrain, trainPartition$classe)
```

## Print out Predicted Values
```{r, echo=TRUE}
predTest

```
